{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# KAGGLE DATASET DOWNLOAD\n",
        "# ================================================================\n",
        "\n",
        "USE_KAGGLE_DOWNLOAD = True   # <--- Set to False if you want manual files\n",
        "\n",
        "if USE_KAGGLE_DOWNLOAD:\n",
        "    print(\"=== Downloading dataset from Kaggle ===\")\n",
        "\n",
        "    # Install Kaggle API\n",
        "    !pip install -q kaggle\n",
        "\n",
        "    # Create kaggle directory\n",
        "    import os\n",
        "    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "    # Write your kaggle.json (you must upload kaggle.json once)\n",
        "    from google.colab import files\n",
        "    print(\"Please upload your kaggle.json file.\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move kaggle.json into API folder\n",
        "    for fn in uploaded.keys():\n",
        "        os.rename(fn, \"/root/.kaggle/kaggle.json\")\n",
        "    os.chmod(\"/root/.kaggle/kaggle.json\", 600)\n",
        "\n",
        "    # Download the dataset\n",
        "    # NOTE: update this to your dataset's Kaggle slug\n",
        "    # Example: \"cicdataset/ids-2018\" or whatever your dataset is named\n",
        "    DATASET_SLUG = \"cicdataset/cicids2018\"\n",
        "    !kaggle datasets download -d $DATASET_SLUG -p /content/raw_ids_data\n",
        "\n",
        "    # Unzip downloaded files\n",
        "    !unzip -q \"/content/raw_ids_data/*.zip\" -d /content/raw_ids_data\n",
        "\n",
        "    print(\"Kaggle dataset downloaded & extracted.\")\n"
      ],
      "metadata": {
        "id": "T_CiiXK0wy7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Colab-ready training script for IDS ensemble + Keras attention model\n",
        "# Save as train_ensemble_colab.py or paste into a Colab notebook cell.\n",
        "# BEFORE RUN: Upload your cleaned CSV to Colab (or mount Google Drive) and set DATA_PATH.\n",
        "\n",
        "# ---------------------------\n",
        "# 0) Environment / dependencies\n",
        "# ---------------------------\n",
        "# Run these in a notebook cell once:\n",
        "!pip install --upgrade pip\n",
        "!pip install xgboost lightgbm imbalanced-learn joblib cpuinfo tensorflow==2.12.0  # or use TF version available on Colab\n",
        "# (If you don't need LightGBM/XGBoost, remove them — but they help for ensemble.)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxLeMK6ccwYK",
        "outputId": "6688d058-3a74-41a9-8014-058add755ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.3-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.3\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cpuinfo (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for cpuinfo\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 1) Imports\n",
        "# ---------------------------\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from pprint import pprint\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
        "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# xgboost / lightgbm\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# imblearn (optional)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# tensorflow / keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Dropout, Dense, Bidirectional, LSTM, GlobalAveragePooling1D, MultiHeadAttention\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# small safety print\n",
        "print(\"TF version:\", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjMhmJsWd5VK",
        "outputId": "09339787-c2e7-4632-9e65-9a21937ae813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 1.5)(OPTIONAL) RAW DATA CLEANING BLOCK — SAME BEHAVIOUR AS ORIGINAL\n",
        "# ================================================================\n",
        "# Only run this section if you are giving raw CSVs as input.\n",
        "# If you already have cleaned_data_sampled.csv, SKIP THIS.\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "RAW_DATA_DIR = \"/content/raw_ids_data\"   # <--- put all ORIGINAL CSV files here\n",
        "CLEANED_OUTPUT = \"/content/cleaned_data_sampled.csv\"\n",
        "\n",
        "RUN_DATA_CLEANING = True  # set False if you already have cleaned file\n",
        "\n",
        "if RUN_DATA_CLEANING:\n",
        "    print(\"=== RAW DATA CLEANING START ===\")\n",
        "\n",
        "    # Step 1: Load all files\n",
        "    file_paths = []\n",
        "    for root, dirs, filenames in os.walk(RAW_DATA_DIR):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith(\".csv\"):\n",
        "                file_paths.append(os.path.join(root, filename))\n",
        "\n",
        "    # Remove problematic file (same as original code)\n",
        "    bad_file = \"02-20-2018.csv\"\n",
        "    file_paths = [f for f in file_paths if bad_file not in f]\n",
        "\n",
        "    print(\"Found input files:\", len(file_paths))\n",
        "\n",
        "    # Step 2: Combine\n",
        "    df = pd.DataFrame()\n",
        "    for f in file_paths:\n",
        "        print(\"Loading:\", f)\n",
        "        chunk = pd.read_csv(f, low_memory=False)\n",
        "        df = pd.concat([df, chunk], ignore_index=True)\n",
        "\n",
        "    # Remove Timestamp column (matches original)\n",
        "    if \"Timestamp\" in df.columns:\n",
        "        df.drop(columns=[\"Timestamp\"], inplace=True)\n",
        "\n",
        "    print(\"Shape after merging:\", df.shape)\n",
        "\n",
        "    # Step 3: Remove rare classes (same as original)\n",
        "    rare_targets = [\n",
        "        'DoS attacks-Slowloris',\n",
        "        'DDOS attack-LOIC-UDP',\n",
        "        'Brute Force -Web',\n",
        "        'Brute Force -XSS',\n",
        "        'SQL Injection',\n",
        "        'Label'  # erroneous concatenated label\n",
        "    ]\n",
        "    df = df[~df['Label'].isin(rare_targets)]\n",
        "\n",
        "    # Step 4: Sample 41,500 per class\n",
        "    df = df.groupby(\"Label\", group_keys=False).sample(n=41500, random_state=42)\n",
        "\n",
        "    # Step 5: Clean non-numeric → LabelEncode → drop NaNs\n",
        "    encoder = LabelEncoder()\n",
        "    df['Label'] = encoder.fit_transform(df['Label'])\n",
        "\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna()\n",
        "\n",
        "    # Step 6: Downsample after cleaning to 40,000 per class\n",
        "    df = df.groupby(\"Label\", group_keys=False).sample(n=40000, random_state=42)\n",
        "\n",
        "    print(\"\\nFinal cleaned label counts:\")\n",
        "    print(df[\"Label\"].value_counts())\n",
        "\n",
        "    # Step 7: Save cleaned dataset\n",
        "    df.to_csv(CLEANED_OUTPUT, index=False)\n",
        "    print(\"\\nSaved cleaned dataset to:\", CLEANED_OUTPUT)\n",
        "\n",
        "    # Save label encoder\n",
        "    joblib.dump(encoder, \"/content/models/label_encoder.joblib\")\n",
        "    print(\"Saved label encoder.\")\n",
        "    print(\"=== RAW DATA CLEANING COMPLETE ===\\n\")\n"
      ],
      "metadata": {
        "id": "3n67NbTJrfMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 2) Config / Paths / hyperparams\n",
        "# ---------------------------\n",
        "DATA_PATH = \"/content/cleaned_data_sampled.csv\"  # change to your uploaded path or Drive mount path\n",
        "OUTPUT_DIR = \"/content/models\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "SAMPLE_N_PER_CLASS = None  # set to int to resample per class (or None to use full cleaned CSV)\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "USE_SMOTE = False  # try True if class imbalance is severe\n",
        "\n",
        "# SKLearn ensemble hyperparams\n",
        "KBEST_K = 30   # how many features to select for traditional ML models\n",
        "STACK_FINAL_EST = LogisticRegression(max_iter=500, solver=\"saga\")  # meta-learner for stacking\n",
        "\n",
        "# Keras model hyperparams\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 50\n",
        "LR = 1e-4\n",
        "\n"
      ],
      "metadata": {
        "id": "P4X3Og3gdMIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gwvGhqGzyvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 3) Load dataset (CSV)\n",
        "# ---------------------------\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    raise FileNotFoundError(f\"Data file not found at {DATA_PATH}. Upload it to Colab and set DATA_PATH accordingly.\")\n",
        "\n",
        "print(\"Loading data:\", DATA_PATH)\n",
        "df = pd.read_csv(DATA_PATH, low_memory=False)\n",
        "print(\"Raw shape:\", df.shape)\n",
        "print(df['Label'].value_counts())\n",
        "\n",
        "# If you saved Label as integer already, fine. If Label is string, use LabelEncoder\n",
        "if df['Label'].dtype == object or df['Label'].nunique() > 20:\n",
        "    le = LabelEncoder()\n",
        "    df['Label'] = le.fit_transform(df['Label'])\n",
        "    joblib.dump(le, os.path.join(OUTPUT_DIR, \"label_encoder.joblib\"))\n",
        "    print(\"Saved LabelEncoder and classes:\", le.classes_)\n",
        "else:\n",
        "    le = None\n",
        "\n",
        "# Optionally resample per-class (if you want balanced subset)\n",
        "if SAMPLE_N_PER_CLASS is not None:\n",
        "    df = df.groupby('Label', group_keys=False).sample(n=SAMPLE_N_PER_CLASS, random_state=RANDOM_STATE)\n",
        "    print(\"Resampled df shape:\", df.shape)\n",
        "\n",
        "# Ensure numeric & drop NA\n",
        "df = df.apply(pd.to_numeric, errors='coerce')\n",
        "df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
        "print(\"After cleaning shape:\", df.shape)\n",
        "print(\"Label distribution:\\n\", df['Label'].value_counts())\n",
        "\n"
      ],
      "metadata": {
        "id": "O3xmIZ8FdRL4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "585ba476-b4a1-4c70-e39d-f09568c88897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data: /content/cleaned_data_sampled.csv\n",
            "Raw shape: (13476, 79)\n",
            "Label\n",
            "0.0    13475\n",
            "Name: count, dtype: int64\n",
            "After cleaning shape: (13475, 79)\n",
            "Label distribution:\n",
            " Label\n",
            "0.0    13475\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 4) Train / test split & scaler & variance threshold\n",
        "# ---------------------------\n",
        "X = df.drop(columns=['Label'])\n",
        "y = df['Label'].astype(int)\n",
        "\n",
        "# Keep column names for later (for feature selection / production)\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
        ")\n",
        "\n",
        "# Remove near-constant features (trained on train set only)\n",
        "var_selector = VarianceThreshold(threshold=0.01)\n",
        "X_train_var = var_selector.fit_transform(X_train_raw)\n",
        "X_test_var  = var_selector.transform(X_test_raw)\n",
        "selected_var_cols = [feature_names[i] for i in range(len(feature_names)) if var_selector.get_support()[i]]\n",
        "print(\"Kept features after VarianceThreshold:\", len(selected_var_cols))\n",
        "\n",
        "# Robust scaling (fit on train)\n",
        "scaler = RobustScaler(quantile_range=(5.0, 95.0))\n",
        "X_train_scaled = scaler.fit_transform(X_train_var)\n",
        "X_test_scaled  = scaler.transform(X_test_var)\n",
        "\n",
        "# Save selector and scaler\n",
        "joblib.dump(var_selector, os.path.join(OUTPUT_DIR, \"variance_selector.joblib\"))\n",
        "joblib.dump(scaler, os.path.join(OUTPUT_DIR, \"robust_scaler.joblib\"))\n",
        "print(\"Saved variance selector & scaler.\")\n",
        "\n",
        "# Optionally apply SMOTE (only on training data)\n",
        "if USE_SMOTE:\n",
        "    sm = SMOTE(random_state=RANDOM_STATE, n_jobs=-1)\n",
        "    X_train_scaled, y_train = sm.fit_resample(X_train_scaled, y_train)\n",
        "    print(\"Applied SMOTE. New train shape:\", X_train_scaled.shape, y_train.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "nW81jtxedVKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "886a3bbd-16c4-4183-c23e-778e0b72bbe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kept features after VarianceThreshold: 67\n",
            "Saved variance selector & scaler.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 5) Prepare datasets for Keras model (3D)\n",
        "# ---------------------------\n",
        "# We will use the scaled & selected features\n",
        "X_train_cnn = X_train_scaled[..., np.newaxis].astype(\"float32\")\n",
        "X_test_cnn  = X_test_scaled[..., np.newaxis].astype(\"float32\")\n",
        "num_classes = int(np.unique(y).shape[0])\n",
        "y_train_cnn = to_categorical(y_train, num_classes=num_classes)\n",
        "y_test_cnn  = to_categorical(y_test,  num_classes=num_classes)\n",
        "\n",
        "print(\"Keras input shapes:\", X_train_cnn.shape, X_test_cnn.shape, \"num_classes:\", num_classes)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qHW_NVH0dZtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd800d72-eb41-437e-8606-4e87a8ebfaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras input shapes: (10780, 67, 1) (2695, 67, 1) num_classes: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 6) Build Keras CNN+BiLSTM+Attention model (cleaned)\n",
        "# ---------------------------\n",
        "timesteps = X_train_cnn.shape[1]\n",
        "channels = X_train_cnn.shape[2]\n",
        "\n",
        "def build_attn_model(timesteps, channels, num_classes, l2_reg=1e-3):\n",
        "    inputs = Input(shape=(timesteps, channels), name=\"inputs\")\n",
        "    x = Conv1D(128, 3, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(2, padding='same')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Conv1D(256, 3, activation='relu', padding='same', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling1D(2, padding='same')(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "\n",
        "    x = Bidirectional(LSTM(128, return_sequences=True), name=\"bilstm\")(x)\n",
        "\n",
        "    # Multi-head attention expects shape (batch, seq_len, dim)\n",
        "    attn_out = MultiHeadAttention(num_heads=4, key_dim=64, name=\"mha\")(x, x)\n",
        "    x = x + attn_out\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = GlobalAveragePooling1D(name=\"gap\")(x)\n",
        "    x = Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "    x = Dropout(0.3)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax', name=\"softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"CNN_BiLSTM_Attn\")\n",
        "    return model\n",
        "\n",
        "attn_model = build_attn_model(timesteps, channels, num_classes)\n",
        "attn_model.summary()\n",
        "\n",
        "# compile\n",
        "attn_model.compile(\n",
        "    optimizer=Adam(learning_rate=LR),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', tf.keras.metrics.Precision(name='Precision'), tf.keras.metrics.Recall(name='Recall')]\n",
        ")\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True),\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6),\n",
        "    tf.keras.callbacks.TerminateOnNaN()\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "xM-Y9oWJdeVg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "57fc14a5-b78a-4708-bcc7-bdac78dc086b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"CNN_BiLSTM_Attn\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_BiLSTM_Attn\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ inputs[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m67\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m512\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │     \u001b[38;5;34m98,560\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ max_pooling1d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m394,240\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m263,168\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bilstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                     │                   │            │ mha[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │      \u001b[38;5;34m1,024\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gap                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ gap[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">67</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling1d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,240</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ mha                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bilstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                     │                   │            │ mha[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gap                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ gap[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m792,065\u001b[0m (3.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">792,065</span> (3.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m790,785\u001b[0m (3.02 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">790,785</span> (3.02 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 7) Train Keras model (optional, can be skipped to only train sklearn ensemble)\n",
        "# ---------------------------\n",
        "use_train_keras = True\n",
        "if use_train_keras:\n",
        "    t0 = time.time()\n",
        "    history_attn = attn_model.fit(\n",
        "        X_train_cnn, y_train_cnn,\n",
        "        validation_data=(X_test_cnn, y_test_cnn),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "    print(\"Keras training time (seconds):\", time.time() - t0)\n",
        "    # Save Keras model\n",
        "    attn_model.save(os.path.join(OUTPUT_DIR, \"attn_model.h5\"))\n",
        "    print(\"Saved Keras model to\", os.path.join(OUTPUT_DIR, \"attn_model.h5\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "16WP-0Uidi9A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54a6ef6-d097-4fc2-a52f-64ef299adbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/losses/losses.py:33: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.3318 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.2983 - learning_rate: 1.0000e-04\n",
            "Epoch 2/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.2880 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.2588 - learning_rate: 1.0000e-04\n",
            "Epoch 3/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.2499 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.2245 - learning_rate: 1.0000e-04\n",
            "Epoch 4/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.2168 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1947 - learning_rate: 1.0000e-04\n",
            "Epoch 5/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.1880 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1689 - learning_rate: 1.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.1630 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1464 - learning_rate: 1.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.1413 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1268 - learning_rate: 1.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.1224 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1098 - learning_rate: 1.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.1060 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0951 - learning_rate: 1.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0917 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0823 - learning_rate: 1.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0794 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0711 - learning_rate: 1.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0687 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0615 - learning_rate: 1.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0594 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0532 - learning_rate: 1.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0513 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0459 - learning_rate: 1.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0443 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0397 - learning_rate: 1.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0383 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0342 - learning_rate: 1.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0330 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0296 - learning_rate: 1.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0285 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0255 - learning_rate: 1.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0246 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0220 - learning_rate: 1.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0212 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0189 - learning_rate: 1.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0182 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0163 - learning_rate: 1.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0157 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0140 - learning_rate: 1.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0135 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0120 - learning_rate: 1.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0116 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0103 - learning_rate: 1.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0100 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0089 - learning_rate: 1.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0085 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0076 - learning_rate: 1.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0073 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0065 - learning_rate: 1.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0062 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0055 - learning_rate: 1.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0053 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0047 - learning_rate: 1.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0045 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0040 - learning_rate: 1.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0038 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0034 - learning_rate: 1.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0032 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0029 - learning_rate: 1.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0027 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0024 - learning_rate: 1.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0023 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0020 - learning_rate: 1.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0019 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0017 - learning_rate: 1.0000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0016 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0014 - learning_rate: 1.0000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0014 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 0.0011 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.7603e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 9.3177e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 8.0646e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 7.6921e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 6.6385e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 6.3260e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 5.4434e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 5.1822e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 4.4456e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 4.2281e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 3.6156e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 3.4353e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.9282e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 2.7792e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 2.3610e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 2.2386e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.8952e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 1.7950e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.5143e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 1.4326e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 1.2042e-04 - learning_rate: 1.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 1.1380e-04 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 9.5304e-05 - learning_rate: 1.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - Precision: 1.0000 - Recall: 1.0000 - accuracy: 1.0000 - loss: 8.9954e-05 - val_Precision: 1.0000 - val_Recall: 1.0000 - val_accuracy: 1.0000 - val_loss: 7.5051e-05 - learning_rate: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keras training time (seconds): 107.17187333106995\n",
            "Saved Keras model to /content/models/attn_model.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 8) Build classical ML base models (with SelectKBest inside pipelines)\n",
        "# ---------------------------\n",
        "# We'll use XGBoost, RandomForest, and a DecisionTree or NaiveBayes as diverse base learners.\n",
        "# Important: SelectKBest must be fit on training data; to simplify, we'll apply SelectKBest on scaled arrays.\n",
        "\n",
        "# Fit SelectKBest on the scaled training arrays (so we can use transformed arrays downstream)\n",
        "kbest = SelectKBest(f_classif, k=min(KBEST_K, X_train_scaled.shape[1]))\n",
        "# Suppress warning if kbest runs on single-class data\n",
        "import warnings\n",
        "with warnings.catch_warnings():\n",
        "    warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
        "    X_train_kbest = kbest.fit_transform(X_train_scaled, y_train)\n",
        "X_test_kbest  = kbest.transform(X_test_scaled)\n",
        "\n",
        "joblib.dump(kbest, os.path.join(OUTPUT_DIR, \"select_kbest.joblib\"))\n",
        "print(\"Saved SelectKBest (k={}):\".format(kbest.k))\n",
        "\n",
        "# Base estimators\n",
        "base_estimators = [\n",
        "    (\"rf\", RandomForestClassifier(n_estimators=200, max_depth=14, n_jobs=-1, random_state=RANDOM_STATE))\n",
        "]\n",
        "\n",
        "# Conditionally add XGBoost and LightGBM if there are multiple classes\n",
        "if num_classes > 1:\n",
        "    base_estimators.append((\"xgb\", xgb.XGBClassifier(n_estimators=200, use_label_encoder=False, eval_metric=\"mlogloss\", verbosity=0, random_state=RANDOM_STATE)))\n",
        "    base_estimators.append((\"lgb\", lgb.LGBMClassifier(n_estimators=200, random_state=RANDOM_STATE)))\n",
        "else:\n",
        "    print(f\"\\nWarning: Only {num_classes} class found in the dataset. Skipping XGBoost and LightGBM as they require multiple classes for meaningful classification.\")\n",
        "\n",
        "# Train base estimators on the K-best features\n",
        "for name, est in base_estimators:\n",
        "    print(f\"Training base model: {name}\")\n",
        "    t0 = time.time()\n",
        "    est.fit(X_train_kbest, y_train)\n",
        "    elapsed = time.time() - t0\n",
        "    print(f\"Trained {name} in {elapsed:.2f}s\")\n",
        "    joblib.dump(est, os.path.join(OUTPUT_DIR, f\"{name}_model.joblib\"))\n",
        "\n",
        "# Evaluate base estimators quickly\n",
        "for name, est in base_estimators:\n",
        "    ypred = est.predict(X_test_kbest)\n",
        "    print(f\"\\n{name} metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, ypred))\n",
        "    print(\"Precision:\", precision_score(y_test, ypred, average='weighted', zero_division=0))\n",
        "    print(\"Recall:\", recall_score(y_test, ypred, average='weighted', zero_division=0))\n",
        "    print(\"F1:\", f1_score(y_test, ypred, average='weighted', zero_division=0))\n"
      ],
      "metadata": {
        "id": "XyqzhJFEdmVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4282bd5a-e8e5-4e9b-f17a-af6807069cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved SelectKBest (k=30):\n",
            "\n",
            "Warning: Only 1 class found in the dataset. Skipping XGBoost and LightGBM as they require multiple classes for meaningful classification.\n",
            "Training base model: rf\n",
            "Trained rf in 0.49s\n",
            "\n",
            "rf metrics:\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 9) Build stacking classifier (meta-learner)\n",
        "# ---------------------------\n",
        "estimators_for_stack = [(n, e) for n, e in base_estimators]\n",
        "\n",
        "if num_classes > 1:\n",
        "    stack = StackingClassifier(\n",
        "        estimators=estimators_for_stack,\n",
        "        final_estimator=STACK_FINAL_EST,\n",
        "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
        "        n_jobs=-1,\n",
        "        passthrough=False\n",
        "    )\n",
        "\n",
        "    print(\"Training StackingClassifier on K-best features...\")\n",
        "    t0 = time.time()\n",
        "    stack.fit(X_train_kbest, y_train)\n",
        "    print(\"Stack trained in {:.2f}s\".format(time.time() - t0))\n",
        "    joblib.dump(stack, os.path.join(OUTPUT_DIR, \"stacking_model.joblib\"))\n",
        "    print(\"Saved stacking model\")\n",
        "\n",
        "    # Evaluate stacking\n",
        "    y_stack_pred = stack.predict(X_test_kbest)\n",
        "    print(\"\\nStacking metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_stack_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_stack_pred, average='weighted', zero_division=0))\n",
        "    print(\"Recall:\", recall_score(y_test, y_stack_pred, average='weighted', zero_division=0))\n",
        "    print(\"F1:\", f1_score(y_test, y_stack_pred, average='weighted', zero_division=0))\n",
        "    print(classification_report(y_test, y_stack_pred, zero_division=0))\n",
        "else:\n",
        "    print(f\"\\nSkipping StackingClassifier training and evaluation as only {num_classes} class found in the dataset.\")\n",
        "    stack = None # Ensure 'stack' variable is defined even if not trained\n"
      ],
      "metadata": {
        "id": "uI8cwGJbdqYz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc92265-e114-499e-b745-733a1ce9c7d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Skipping StackingClassifier training and evaluation as only 1 class found in the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 10) Optionally build a Voting ensemble that includes the stacking + another external model\n",
        "# ---------------------------\n",
        "\n",
        "if num_classes > 1 and stack is not None:\n",
        "    voting_clf = VotingClassifier(\n",
        "        estimators=[\n",
        "            (\"stack\", stack),\n",
        "            (\"rf\", base_estimators[0][1]),  # using already trained RF\n",
        "        ],\n",
        "        voting=\"soft\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    print(\"Training Voting ensemble (stack + rf)...\")\n",
        "    voting_clf.fit(X_train_kbest, y_train)\n",
        "    joblib.dump(voting_clf, os.path.join(OUTPUT_DIR, \"voting_ensemble.joblib\"))\n",
        "    print(\"Saved voting ensemble\")\n",
        "\n",
        "    # Evaluate voting\n",
        "    y_vote_pred = voting_clf.predict(X_test_kbest)\n",
        "    print(\"\\nVoting ensemble metrics:\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_vote_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_vote_pred, average='weighted', zero_division=0))\n",
        "    print(\"Recall:\", recall_score(y_test, y_vote_pred, average='weighted', zero_division=0))\n",
        "    print(\"F1:\", f1_score(y_test, y_vote_pred, average='weighted', zero_division=0))\n",
        "else:\n",
        "    print(f\"\\nSkipping Voting ensemble training and evaluation as only {num_classes} class found in the dataset or StackingClassifier was skipped.\")\n"
      ],
      "metadata": {
        "id": "rCH5nIkwds-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c6fb9d-6e7f-404b-ec78-faca73f6ef23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Skipping Voting ensemble training and evaluation as only 1 class found in the dataset or StackingClassifier was skipped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 11) Save metadata (selected feature names after variance & KBest)\n",
        "# ---------------------------\n",
        "# Compute final selected column names (variance selector -> then kbest)\n",
        "# var_selector support -> selected_var_cols already computed earlier\n",
        "# Now map kbest selected indices to actual names:\n",
        "kbest_support_mask = kbest.get_support()\n",
        "final_feature_names = [selected_var_cols[i] for i in range(len(selected_var_cols)) if kbest_support_mask[i]]\n",
        "print(\"Final features used for ML models:\", len(final_feature_names))\n",
        "joblib.dump(final_feature_names, os.path.join(OUTPUT_DIR, \"final_feature_names.joblib\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "YXUYE_addv2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16da5b36-f168-4bdb-a3a4-4c3bb23d8a2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final features used for ML models: 30\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/models/final_feature_names.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 12) Inference helper functions (load models, do preprocessing)\n",
        "# ---------------------------\n",
        "def load_production_artifacts(models_dir=OUTPUT_DIR):\n",
        "    artifacts = {}\n",
        "    artifacts['variance_selector'] = joblib.load(os.path.join(models_dir, \"variance_selector.joblib\"))\n",
        "    artifacts['robust_scaler']   = joblib.load(os.path.join(models_dir, \"robust_scaler.joblib\"))\n",
        "    artifacts['select_kbest']    = joblib.load(os.path.join(models_dir, \"select_kbest.joblib\"))\n",
        "    artifacts['stack']           = joblib.load(os.path.join(models_dir, \"stacking_model.joblib\"))\n",
        "    artifacts['voting']          = joblib.load(os.path.join(models_dir, \"voting_ensemble.joblib\"))\n",
        "    # Load label encoder if saved\n",
        "    le_path = os.path.join(models_dir, \"label_encoder.joblib\")\n",
        "    if os.path.exists(le_path):\n",
        "        artifacts['label_encoder'] = joblib.load(le_path)\n",
        "    # Keras model load (optional)\n",
        "    keras_path = os.path.join(models_dir, \"attn_model.h5\")\n",
        "    if os.path.exists(keras_path):\n",
        "        artifacts['attn_model'] = tf.keras.models.load_model(keras_path)\n",
        "    return artifacts\n",
        "\n",
        "def preprocess_for_ml(raw_df, artifacts):\n",
        "    # raw_df: pandas df with same original columns (before variance selection)\n",
        "    Xv = artifacts['variance_selector'].transform(raw_df)\n",
        "    Xs = artifacts['robust_scaler'].transform(Xv)\n",
        "    Xk = artifacts['select_kbest'].transform(Xs)\n",
        "    return Xk\n",
        "\n",
        "def predict_sample(raw_df, artifacts):\n",
        "    Xk = preprocess_for_ml(raw_df, artifacts)\n",
        "    # get probabilities from voting ensemble, stacking, and optionally keras\n",
        "    probs_vote = artifacts['voting'].predict_proba(Xk)\n",
        "    probs_stack = artifacts['stack'].predict_proba(Xk)\n",
        "    result = {\n",
        "        'voting_pred': np.argmax(probs_vote, axis=1),\n",
        "        'voting_proba': probs_vote,\n",
        "        'stack_pred': np.argmax(probs_stack, axis=1),\n",
        "        'stack_proba': probs_stack\n",
        "    }\n",
        "    if 'attn_model' in artifacts:\n",
        "        # we need 3D input for attn_model\n",
        "        Xs = artifacts['robust_scaler'].transform(artifacts['variance_selector'].transform(raw_df))\n",
        "        Xc = artifacts['select_kbest'].transform(Xs)  # NOTE: Keras used all features earlier; adapt if needed\n",
        "        Xc = Xc[..., np.newaxis].astype(\"float32\")\n",
        "        result['attn_pred'] = np.argmax(artifacts['attn_model'].predict(Xc), axis=1)\n",
        "    return result\n",
        "\n"
      ],
      "metadata": {
        "id": "K-49GEUndyvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# 13) Final prints\n",
        "# ---------------------------\n",
        "print(\"\\nAll models saved in:\", OUTPUT_DIR)\n",
        "print(\"You can now download models or move them to Google Drive for production deployment.\")"
      ],
      "metadata": {
        "id": "E-TOYf5md0st",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac668cd-d92d-4a4b-d7f0-4f0dbcb38929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All models saved in: /content/models\n",
            "You can now download models or move them to Google Drive for production deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# 14) Plot accuracy comparison of all models\n",
        "# ================================================================\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\nPreparing accuracy comparison plot...\")\n",
        "\n",
        "model_names = []\n",
        "accuracies = []\n",
        "\n",
        "# 1. Base learners\n",
        "for name, est in base_estimators:\n",
        "    y_pred = est.predict(X_test_kbest)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    model_names.append(name.upper())\n",
        "    accuracies.append(acc)\n",
        "\n",
        "# 2. Stacking ensemble (conditional)\n",
        "if 'stack' in locals() and stack is not None:\n",
        "    y_stack_pred = stack.predict(X_test_kbest)\n",
        "    acc_stack = accuracy_score(y_test, y_stack_pred)\n",
        "    model_names.append(\"STACKING\")\n",
        "    accuracies.append(acc_stack)\n",
        "\n",
        "# 3. Voting ensemble (conditional)\n",
        "if 'voting_clf' in locals() and voting_clf is not None:\n",
        "    y_vote_pred = voting_clf.predict(X_test_kbest)\n",
        "    acc_vote = accuracy_score(y_test, y_vote_pred)\n",
        "    model_names.append(\"VOTING\")\n",
        "    accuracies.append(acc_vote)\n",
        "\n",
        "# 4. CNN Attention model (optional — only if trained)\n",
        "if \"attn_model\" in locals():\n",
        "    y_attn_pred = np.argmax(attn_model.predict(X_test_cnn, verbose=0), axis=1)\n",
        "    acc_attn = accuracy_score(y_test, y_attn_pred)\n",
        "    model_names.append(\"CNN_ATTENTION\")\n",
        "    accuracies.append(acc_attn)\n",
        "\n",
        "# ---- Plot ----\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(model_names, accuracies)\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAccuracies:\")\n",
        "for n, a in zip(model_names, accuracies):\n",
        "    print(f\"{n}: {a:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "id": "SHjRuu5G3eYP",
        "outputId": "568e8f9d-e576-4b75-d534-2959d99752af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing accuracy comparison plot...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (32, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/ops/nn.py:944: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracies:\n",
            "RF: 1.0000\n",
            "CNN_ATTENTION: 1.0000\n"
          ]
        }
      ]
    }
  ]
}